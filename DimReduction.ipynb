{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#James Chartouni\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import scipy\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "# Import the 3 dimensionality reduction methods\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD, FastICA\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4459, Columns: 1420\n",
      "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  adf119b9a  0d866c3d7  \\\n",
      "0        103      4628   0.000000        0.0        0.0        0.0        0.0   \n",
      "1         68      4663  14.603968        0.0        0.0        0.0        0.0   \n",
      "2         19      4712   0.000000        0.0        0.0        0.0        0.0   \n",
      "3         23      4708   0.000000        0.0        0.0        0.0        0.0   \n",
      "4         27      4704  14.508658        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   bd8f989f1  22ed6dba3  92b13ebba       ...             Std  Q4.95  \\\n",
      "0        0.0        0.0        0.0       ...        2.169096    0.0   \n",
      "1        0.0        0.0        0.0       ...        1.809385    0.0   \n",
      "2        0.0        0.0        0.0       ...        0.909701    0.0   \n",
      "3        0.0        0.0        0.0       ...        0.887781    0.0   \n",
      "4        0.0        0.0        0.0       ...        1.098374    0.0   \n",
      "\n",
      "          Q5       Skew       mad        kurt       sem  number_of_different  \\\n",
      "0  17.504390   6.680490  0.627328   43.068786  0.031539                   63   \n",
      "1  17.727534   8.285303  0.426605   67.033615  0.026309                   33   \n",
      "2  16.300417  16.285642  0.111617  264.921101  0.013227                   22   \n",
      "3  15.607270  15.013488  0.119476  227.401614  0.012908                   23   \n",
      "4  17.444162  13.627510  0.161356  185.763814  0.015971                   25   \n",
      "\n",
      "   non_zero_count  geometric_mean  \n",
      "0             115       14.975334  \n",
      "1              80       14.998494  \n",
      "2              31       11.806805  \n",
      "3              35       11.124137  \n",
      "4              39       12.893002  \n",
      "\n",
      "[5 rows x 1420 columns]\n",
      "Rows: 49342, Columns: 1420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SumValues</th>\n",
       "      <th>SumZeros</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>4681de4fd</th>\n",
       "      <th>adf119b9a</th>\n",
       "      <th>0d866c3d7</th>\n",
       "      <th>bd8f989f1</th>\n",
       "      <th>22ed6dba3</th>\n",
       "      <th>92b13ebba</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Q4.95</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Skew</th>\n",
       "      <th>mad</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sem</th>\n",
       "      <th>number_of_different</th>\n",
       "      <th>non_zero_count</th>\n",
       "      <th>geometric_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>4658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.829730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.682969</td>\n",
       "      <td>8.348649</td>\n",
       "      <td>0.438792</td>\n",
       "      <td>69.445898</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>14.457006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.273869</td>\n",
       "      <td>22.865799</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>534.362437</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>9.579583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.037257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.197537</td>\n",
       "      <td>6.921548</td>\n",
       "      <td>0.576216</td>\n",
       "      <td>46.797912</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>84</td>\n",
       "      <td>112</td>\n",
       "      <td>14.151046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "      <td>4610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.854494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.510632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.420681</td>\n",
       "      <td>6.121881</td>\n",
       "      <td>0.785246</td>\n",
       "      <td>35.733973</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>111</td>\n",
       "      <td>133</td>\n",
       "      <td>16.031065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.494941</td>\n",
       "      <td>24.977718</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>631.998291</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>9.390606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  adf119b9a  0d866c3d7  \\\n",
       "0         73      4658        0.0        0.0        0.0        0.0        0.0   \n",
       "1         11      4720        0.0        0.0        0.0        0.0        0.0   \n",
       "2        100      4631        0.0        0.0        0.0        0.0        0.0   \n",
       "3        121      4610        0.0        0.0        0.0        0.0        0.0   \n",
       "4          9      4722        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   bd8f989f1  22ed6dba3  92b13ebba       ...             Std  Q4.95  \\\n",
       "0   0.000000        0.0        0.0       ...        1.829730    0.0   \n",
       "1   0.000000        0.0        0.0       ...        0.645842    0.0   \n",
       "2   0.000000        0.0        0.0       ...        2.037257    0.0   \n",
       "3  16.854494        0.0        0.0       ...        2.510632    0.0   \n",
       "4   0.000000        0.0        0.0       ...        0.617740    0.0   \n",
       "\n",
       "          Q5       Skew       mad        kurt       sem  number_of_different  \\\n",
       "0  20.682969   8.348649  0.438792   69.445898  0.026605                   83   \n",
       "1  17.273869  22.865799  0.058110  534.362437  0.009391                   21   \n",
       "2  18.197537   6.921548  0.576216   46.797912  0.029622                   84   \n",
       "3  18.420681   6.121881  0.785246   35.733973  0.036505                  111   \n",
       "4  18.494941  24.977718  0.050213  631.998291  0.008982                   19   \n",
       "\n",
       "   non_zero_count  geometric_mean  \n",
       "0              85       14.457006  \n",
       "1              23        9.579583  \n",
       "2             112       14.151046  \n",
       "3             133       16.031065  \n",
       "4              21        9.390606  \n",
       "\n",
       "[5 rows x 1420 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned.csv\")\n",
    "train_orig = pd.read_csv(\"data/train.csv\")\n",
    "#y_train = train_orig['target'] #TRY A LOG TRANSFORM\n",
    "y = np.log1p(train_orig[\"target\"].values)\n",
    "#y_train = boxcox(train_orig[\"target\"].values)[0]\n",
    "#X_train = train.drop([\"target\", \"ID\"], axis=1)\n",
    "X = train\n",
    "\n",
    "print (\"Rows: \" + str(train.shape[0]) + \", Columns: \" + str(train.shape[1]))\n",
    "print(train.head())\n",
    "\n",
    "test = pd.read_csv('data/test_cleaned.csv')\n",
    "#test_X = test.drop([\"ID\"], axis=1)\n",
    "print (\"Rows: \" + str(test.shape[0]) + \", Columns: \" + str(test.shape[1]))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4459 entries, 0 to 4458\n",
      "Columns: 1420 entries, SumValues to geometric_mean\n",
      "dtypes: float64(1416), int64(4)\n",
      "memory usage: 48.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49342 entries, 0 to 49341\n",
      "Columns: 1420 entries, SumValues to geometric_mean\n",
      "dtypes: float64(1416), int64(4)\n",
      "memory usage: 534.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 17.45309674,  13.3046866 ,  16.11809575, ...,  14.84513033,\n",
       "        16.11809575,  16.81124288])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info()\n",
    "test.info()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Features with NaN Values = 0\n"
     ]
    }
   ],
   "source": [
    "#### Check if there are any NULL values in Train Data\n",
    "print(\"Total Train Features with NaN Values = \" + str(X.columns[X.isnull().sum() != 0].size))\n",
    "if (X.columns[X.isnull().sum() != 0].size):\n",
    "    print(\"Features with NaN => {}\".format(list(X.columns[X.isnull().sum() != 0])))\n",
    "    X[X.columns[X.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : 'rmse',\n",
    "        \"num_leaves\" : 50,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42,\n",
    "        'colsample_bytree': 0.48018395169871853,\n",
    "        'max_bin': 349,\n",
    "        'n_estimators': 194,\n",
    "        \"n_threads\": -1,\n",
    "        'reg_alpha': 1.3428918202554421e-06,\n",
    "        'reg_lambda': 0.36738052550567774,\n",
    "        'scale_pos_weight': 0.0077999778087354376,\n",
    "        'subsample': 0.72080408790270512,\n",
    "        'subsample_for_bin': 413393,\n",
    "        'subsample_freq': 8\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 200,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    #\"min_split_gain\":0.2,\n",
    "    \"min_child_weight\":10,\n",
    "    'zero_as_missing':True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgtrain, lgval],\n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    #pred_test_y = inv_boxcox(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization \n",
    "#minMax_train = MinMaxScaler().fit_transform(X_train.values)\n",
    "#standardScaler_train = StandardScaler().fit_transform(X_train.values)\n",
    "#robustScaler_train = RobustScaler().fit_transform(X_train.values)\n",
    "maxAbsScaler_train = MaxAbsScaler().fit_transform(X.values)\n",
    "\n",
    "\n",
    "#minMax_test = MinMaxScaler().fit_transform(test_X.values)\n",
    "#standardScaler_test = StandardScaler().fit_transform(test_X.values)\n",
    "#robustScaler_test = RobustScaler().fit_transform(test_X.values)\n",
    "maxAbsScaler_test = MaxAbsScaler().fit_transform(test.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start decomposition process...\n",
      "PCA\n",
      "[  6.84190249e-01   2.70950982e-01   9.09071526e-03   2.73655643e-03\n",
      "   1.25786486e-03   7.72638444e-04   6.77609470e-04   6.31381632e-04\n",
      "   4.96527570e-04   4.56989667e-04   4.34568787e-04   4.03121171e-04\n",
      "   3.55032209e-04   3.18168560e-04   3.13632850e-04   2.66096493e-04\n",
      "   2.45900721e-04   2.35228760e-04   2.22150305e-04   2.07768187e-04]\n",
      "SparcePCA\n"
     ]
    }
   ],
   "source": [
    "n_components = 20\n",
    "\n",
    "\n",
    "# Convert to sparse matrix\n",
    "sparse_X = scipy.sparse.csr_matrix(X.values)\n",
    "sparse_test = scipy.sparse.csr_matrix(test.values)\n",
    "\n",
    "#try normalizing and standardizing variables before PCA\n",
    "\n",
    "\n",
    "print(\"\\nStart decomposition process...\")\n",
    "\n",
    "print(\"PCA\")\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "pca_results_train = pca.fit_transform(X)\n",
    "pca_results_test = pca.transform(test)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"SparcePCA\")\n",
    "sparce_pca = SparsePCA(n_components=n_components, random_state=42)\n",
    "sparce_pca_results_train = sparce_pca.fit_transform(X)\n",
    "print(\"SparcePCA test\")\n",
    "sparce_pca_results_test = sparce_pca.transform(test)\n",
    "print(sparce_pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"tSVD\")\n",
    "tsvd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "tsvd_results_train = tsvd.fit_transform(X)\n",
    "tsvd_results_test = tsvd.transform(test)\n",
    "\n",
    "print(\"ICA\")\n",
    "ica = FastICA(n_components=n_components, random_state=42)\n",
    "ica_results_train = ica.fit_transform(X)\n",
    "ica_results_test = ica.transform(test)\n",
    "\n",
    "print(\"GRP\")\n",
    "grp = GaussianRandomProjection(n_components=Nn_components_COMP, eps=0.1, random_state=42)\n",
    "grp_results_train = grp.fit_transform(X)\n",
    "grp_results_test = grp.transform(test)\n",
    "\n",
    "print(\"SRP\")\n",
    "srp = SparseRandomProjection(n_components=n_components, dense_output=True, random_state=42)\n",
    "srp_results_train = srp.fit_transform(X)\n",
    "srp_results_test = srp.transform(test)\n",
    "\n",
    "print(\"TSNE\")\n",
    "tsne = TSNE(n_components=n_components, verbose=1, random_state=42, n_iter=500)\n",
    "tsne_results_train = tsne.fit_transform(X)\n",
    "tsne_results_test = tsne.transform(test)\n",
    "\n",
    "#Factor Analysis\n",
    "\n",
    "#Kernel PCA\n",
    "\n",
    "X_train = pd.Dataframe()\n",
    "X_test = pd.Dataframe()\n",
    "\n",
    "print(\"Append decomposition components to datasets...\")\n",
    "for i in range(1, n_components + 1):\n",
    "    X_train['pca_' + str(i)] = pca_results_train[:, i - 1]\n",
    "    X_test['pca_' + str(i)] = pca_results_test[:, i - 1]\n",
    "\n",
    "    X_train['spca_' + str(i)] = sparce_pca_results_train[:, i - 1]\n",
    "    X_test['spca_' + str(i)] = sparce_pca_results_test[:, i - 1]\n",
    "    \n",
    "    X_train['ica_' + str(i)] = ica_results_train[:, i - 1]\n",
    "    X_test['ica_' + str(i)] = ica_results_test[:, i - 1]\n",
    "\n",
    "    X_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    X_test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    X_train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    X_test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    X_train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    X_test['srp_' + str(i)] = srp_results_test[:, i - 1]\n",
    "    \n",
    "    X_train['tsne_' + str(i)] = tsne_results_train[:, i - 1]\n",
    "    X_test['tsne_' + str(i)] = tsne_results_test[:, i - 1]\n",
    "    \n",
    "\n",
    "print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(pca_results_train, y, pca_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparce pca\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(sparce_pca_results_train, y, sparce_pca_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tvsd\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(tsvd_results_train, y, tsvd_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ica\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(ica_results_train, y, ica_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grp\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(grp_results_train, y, grp_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srp\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(srp_results_train, y, srp_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(tsne_results_train, y, tsne_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined features \n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Ran SparseRandomProjection\n"
     ]
    }
   ],
   "source": [
    "COMPONENTS = 20\n",
    "\n",
    "# List of decomposition methods to use\n",
    "methods = [\n",
    "    #TruncatedSVD(n_components=COMPONENTS),\n",
    "    #PCA(n_components=COMPONENTS),\n",
    "    #FastICA(n_components=COMPONENTS),\n",
    "    #GaussianRandomProjection(n_components=COMPONENTS, eps=0.1),\n",
    "    SparseRandomProjection(n_components=COMPONENTS, dense_output=True)    \n",
    "]\n",
    "\n",
    "# Run all the methods\n",
    "embeddings = []\n",
    "for method in methods:\n",
    "    name = method.__class__.__name__    \n",
    "    embeddings.append(\n",
    "        pd.DataFrame(method.fit_transform(X), columns=[f\"{name}_{i}\" for i in range(COMPONENTS)])\n",
    "    )\n",
    "    print(f\">> Ran {name}\")\n",
    "    \n",
    "# Put all components into one dataframe\n",
    "components_df = pd.concat(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SparseRandomProjection_0', 'SparseRandomProjection_1',\n",
      "       'SparseRandomProjection_2', 'SparseRandomProjection_3',\n",
      "       'SparseRandomProjection_4', 'SparseRandomProjection_5',\n",
      "       'SparseRandomProjection_6', 'SparseRandomProjection_7',\n",
      "       'SparseRandomProjection_8', 'SparseRandomProjection_9',\n",
      "       'SparseRandomProjection_10', 'SparseRandomProjection_11',\n",
      "       'SparseRandomProjection_12', 'SparseRandomProjection_13',\n",
      "       'SparseRandomProjection_14', 'SparseRandomProjection_15',\n",
      "       'SparseRandomProjection_16', 'SparseRandomProjection_17',\n",
      "       'SparseRandomProjection_18', 'SparseRandomProjection_19',\n",
      "       'SparseRandomProjection_20', 'SparseRandomProjection_21',\n",
      "       'SparseRandomProjection_22', 'SparseRandomProjection_23',\n",
      "       'SparseRandomProjection_24', 'SparseRandomProjection_25',\n",
      "       'SparseRandomProjection_26', 'SparseRandomProjection_27',\n",
      "       'SparseRandomProjection_28', 'SparseRandomProjection_29',\n",
      "       'SparseRandomProjection_30', 'SparseRandomProjection_31',\n",
      "       'SparseRandomProjection_32', 'SparseRandomProjection_33',\n",
      "       'SparseRandomProjection_34', 'SparseRandomProjection_35',\n",
      "       'SparseRandomProjection_36', 'SparseRandomProjection_37',\n",
      "       'SparseRandomProjection_38', 'SparseRandomProjection_39',\n",
      "       'SparseRandomProjection_40', 'SparseRandomProjection_41',\n",
      "       'SparseRandomProjection_42', 'SparseRandomProjection_43',\n",
      "       'SparseRandomProjection_44', 'SparseRandomProjection_45',\n",
      "       'SparseRandomProjection_46', 'SparseRandomProjection_47',\n",
      "       'SparseRandomProjection_48', 'SparseRandomProjection_49',\n",
      "       'SparseRandomProjection_50', 'SparseRandomProjection_51',\n",
      "       'SparseRandomProjection_52', 'SparseRandomProjection_53',\n",
      "       'SparseRandomProjection_54', 'SparseRandomProjection_55',\n",
      "       'SparseRandomProjection_56', 'SparseRandomProjection_57',\n",
      "       'SparseRandomProjection_58', 'SparseRandomProjection_59',\n",
      "       'SparseRandomProjection_60', 'SparseRandomProjection_61',\n",
      "       'SparseRandomProjection_62', 'SparseRandomProjection_63',\n",
      "       'SparseRandomProjection_64', 'SparseRandomProjection_65',\n",
      "       'SparseRandomProjection_66', 'SparseRandomProjection_67',\n",
      "       'SparseRandomProjection_68', 'SparseRandomProjection_69',\n",
      "       'SparseRandomProjection_70', 'SparseRandomProjection_71',\n",
      "       'SparseRandomProjection_72', 'SparseRandomProjection_73',\n",
      "       'SparseRandomProjection_74', 'SparseRandomProjection_75',\n",
      "       'SparseRandomProjection_76', 'SparseRandomProjection_77',\n",
      "       'SparseRandomProjection_78', 'SparseRandomProjection_79',\n",
      "       'SparseRandomProjection_80', 'SparseRandomProjection_81',\n",
      "       'SparseRandomProjection_82', 'SparseRandomProjection_83',\n",
      "       'SparseRandomProjection_84', 'SparseRandomProjection_85',\n",
      "       'SparseRandomProjection_86', 'SparseRandomProjection_87',\n",
      "       'SparseRandomProjection_88', 'SparseRandomProjection_89'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(components_df.columns)\n",
    "#print(components_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's rmse: 1.48089\tvalid_1's rmse: 1.50144\n",
      "[100]\ttraining's rmse: 1.31385\tvalid_1's rmse: 1.41479\n",
      "[150]\ttraining's rmse: 1.20481\tvalid_1's rmse: 1.37627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[194]\ttraining's rmse: 1.13459\tvalid_1's rmse: 1.3614\n"
     ]
    }
   ],
   "source": [
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's rmse: 1.56835\tvalid_1's rmse: 1.6161\n",
      "[100]\ttraining's rmse: 1.41656\tvalid_1's rmse: 1.5645\n",
      "[150]\ttraining's rmse: 1.29314\tvalid_1's rmse: 1.53023\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[194]\ttraining's rmse: 1.20154\tvalid_1's rmse: 1.51132\n"
     ]
    }
   ],
   "source": [
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(components_df, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Importance model_maxAbsScaler...\n",
      "                      feature      gain  split\n",
      "57  SparseRandomProjection_57  4.329577    230\n",
      "34  SparseRandomProjection_34  3.966076    272\n",
      "53  SparseRandomProjection_53  3.286816    238\n",
      "6    SparseRandomProjection_6  2.714925    184\n",
      "26  SparseRandomProjection_26  2.440892    180\n",
      "75  SparseRandomProjection_75  2.310752    184\n",
      "86  SparseRandomProjection_86  2.177950    185\n",
      "87  SparseRandomProjection_87  1.850851    131\n",
      "67  SparseRandomProjection_67  1.821966    160\n",
      "66  SparseRandomProjection_66  1.805911    166\n",
      "1    SparseRandomProjection_1  1.667898    129\n",
      "22  SparseRandomProjection_22  1.661434    159\n",
      "73  SparseRandomProjection_73  1.639419    129\n",
      "81  SparseRandomProjection_81  1.633417    127\n",
      "8    SparseRandomProjection_8  1.588384    157\n",
      "48  SparseRandomProjection_48  1.584912    127\n",
      "70  SparseRandomProjection_70  1.565727    170\n",
      "65  SparseRandomProjection_65  1.506796    132\n",
      "5    SparseRandomProjection_5  1.481498    127\n",
      "56  SparseRandomProjection_56  1.354396    152\n",
      "20  SparseRandomProjection_20  1.296319    126\n",
      "43  SparseRandomProjection_43  1.241924    133\n",
      "80  SparseRandomProjection_80  1.236672    123\n",
      "64  SparseRandomProjection_64  1.166496     96\n",
      "13  SparseRandomProjection_13  1.161022    117\n",
      "69  SparseRandomProjection_69  1.140429    101\n",
      "89  SparseRandomProjection_89  1.138141    115\n",
      "59  SparseRandomProjection_59  1.123378    106\n",
      "17  SparseRandomProjection_17  1.122882    116\n",
      "21  SparseRandomProjection_21  1.082534    108\n",
      "7    SparseRandomProjection_7  1.080186    110\n",
      "24  SparseRandomProjection_24  1.068194    121\n",
      "55  SparseRandomProjection_55  1.063079    120\n",
      "63  SparseRandomProjection_63  1.056368    101\n",
      "18  SparseRandomProjection_18  1.022820    101\n",
      "40  SparseRandomProjection_40  1.017765    112\n",
      "49  SparseRandomProjection_49  1.011325    100\n",
      "10  SparseRandomProjection_10  1.010587     92\n",
      "27  SparseRandomProjection_27  0.998474    108\n",
      "36  SparseRandomProjection_36  0.982284    119\n",
      "60  SparseRandomProjection_60  0.980604    100\n",
      "62  SparseRandomProjection_62  0.967002     91\n",
      "37  SparseRandomProjection_37  0.932951     97\n",
      "82  SparseRandomProjection_82  0.929136    107\n",
      "68  SparseRandomProjection_68  0.927067     83\n",
      "3    SparseRandomProjection_3  0.917267    101\n",
      "72  SparseRandomProjection_72  0.912850     87\n",
      "38  SparseRandomProjection_38  0.887068    103\n",
      "39  SparseRandomProjection_39  0.882986     95\n",
      "79  SparseRandomProjection_79  0.876310     90\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "print(\"Features Importance model_maxAbsScaler...\")\n",
    "gain = model_lgbm.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model_lgbm.feature_name(), \n",
    "                   'split':model_lgbm.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID        target\n",
      "0  000137c73  2.048776e+06\n",
      "1  00021489f  1.976916e+06\n",
      "2  0004d7953  1.976916e+06\n",
      "3  00056a333  1.992680e+06\n",
      "4  00056d8eb  1.976916e+06\n"
     ]
    }
   ],
   "source": [
    "#LGBM predictions\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test_lgbm\n",
    "\n",
    "sub[\"target\"] = sub_lgb[\"target\"] \n",
    "\n",
    "print(sub.head())\n",
    "sub.to_csv('submit/sub_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#James Chartouni\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4459, Columns: 1420\n",
      "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  adf119b9a  0d866c3d7  \\\n",
      "0        103      4628   0.000000        0.0        0.0        0.0        0.0   \n",
      "1         68      4663  14.603968        0.0        0.0        0.0        0.0   \n",
      "2         19      4712   0.000000        0.0        0.0        0.0        0.0   \n",
      "3         23      4708   0.000000        0.0        0.0        0.0        0.0   \n",
      "4         27      4704  14.508658        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   bd8f989f1  22ed6dba3  92b13ebba       ...             Std  Q4.95  \\\n",
      "0        0.0        0.0        0.0       ...        2.169096    0.0   \n",
      "1        0.0        0.0        0.0       ...        1.809385    0.0   \n",
      "2        0.0        0.0        0.0       ...        0.909701    0.0   \n",
      "3        0.0        0.0        0.0       ...        0.887781    0.0   \n",
      "4        0.0        0.0        0.0       ...        1.098374    0.0   \n",
      "\n",
      "          Q5       Skew       mad        kurt       sem  number_of_different  \\\n",
      "0  17.504390   6.680490  0.627328   43.068786  0.031539                   63   \n",
      "1  17.727534   8.285303  0.426605   67.033615  0.026309                   33   \n",
      "2  16.300417  16.285642  0.111617  264.921101  0.013227                   22   \n",
      "3  15.607270  15.013488  0.119476  227.401614  0.012908                   23   \n",
      "4  17.444162  13.627510  0.161356  185.763814  0.015971                   25   \n",
      "\n",
      "   non_zero_count  geometric_mean  \n",
      "0             115       14.975334  \n",
      "1              80       14.998494  \n",
      "2              31       11.806805  \n",
      "3              35       11.124137  \n",
      "4              39       12.893002  \n",
      "\n",
      "[5 rows x 1420 columns]\n",
      "Rows: 49342, Columns: 1420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SumValues</th>\n",
       "      <th>SumZeros</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>4681de4fd</th>\n",
       "      <th>adf119b9a</th>\n",
       "      <th>0d866c3d7</th>\n",
       "      <th>bd8f989f1</th>\n",
       "      <th>22ed6dba3</th>\n",
       "      <th>92b13ebba</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Q4.95</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Skew</th>\n",
       "      <th>mad</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sem</th>\n",
       "      <th>number_of_different</th>\n",
       "      <th>non_zero_count</th>\n",
       "      <th>geometric_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>4658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.829730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.682969</td>\n",
       "      <td>8.348649</td>\n",
       "      <td>0.438792</td>\n",
       "      <td>69.445898</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>14.457006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.273869</td>\n",
       "      <td>22.865799</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>534.362437</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>9.579583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.037257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.197537</td>\n",
       "      <td>6.921548</td>\n",
       "      <td>0.576216</td>\n",
       "      <td>46.797912</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>84</td>\n",
       "      <td>112</td>\n",
       "      <td>14.151046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "      <td>4610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.854494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.510632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.420681</td>\n",
       "      <td>6.121881</td>\n",
       "      <td>0.785246</td>\n",
       "      <td>35.733973</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>111</td>\n",
       "      <td>133</td>\n",
       "      <td>16.031065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.494941</td>\n",
       "      <td>24.977718</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>631.998291</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>9.390606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  adf119b9a  0d866c3d7  \\\n",
       "0         73      4658        0.0        0.0        0.0        0.0        0.0   \n",
       "1         11      4720        0.0        0.0        0.0        0.0        0.0   \n",
       "2        100      4631        0.0        0.0        0.0        0.0        0.0   \n",
       "3        121      4610        0.0        0.0        0.0        0.0        0.0   \n",
       "4          9      4722        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   bd8f989f1  22ed6dba3  92b13ebba       ...             Std  Q4.95  \\\n",
       "0   0.000000        0.0        0.0       ...        1.829730    0.0   \n",
       "1   0.000000        0.0        0.0       ...        0.645842    0.0   \n",
       "2   0.000000        0.0        0.0       ...        2.037257    0.0   \n",
       "3  16.854494        0.0        0.0       ...        2.510632    0.0   \n",
       "4   0.000000        0.0        0.0       ...        0.617740    0.0   \n",
       "\n",
       "          Q5       Skew       mad        kurt       sem  number_of_different  \\\n",
       "0  20.682969   8.348649  0.438792   69.445898  0.026605                   83   \n",
       "1  17.273869  22.865799  0.058110  534.362437  0.009391                   21   \n",
       "2  18.197537   6.921548  0.576216   46.797912  0.029622                   84   \n",
       "3  18.420681   6.121881  0.785246   35.733973  0.036505                  111   \n",
       "4  18.494941  24.977718  0.050213  631.998291  0.008982                   19   \n",
       "\n",
       "   non_zero_count  geometric_mean  \n",
       "0              85       14.457006  \n",
       "1              23        9.579583  \n",
       "2             112       14.151046  \n",
       "3             133       16.031065  \n",
       "4              21        9.390606  \n",
       "\n",
       "[5 rows x 1420 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned.csv\")\n",
    "train_orig = pd.read_csv(\"data/train.csv\")\n",
    "#y_train = train_orig['target'] #TRY A LOG TRANSFORM\n",
    "y_train = np.log1p(train_orig[\"target\"].values)\n",
    "#y_train = boxcox(train_orig[\"target\"].values)[0]\n",
    "#X_train = train.drop([\"target\", \"ID\"], axis=1)\n",
    "X_train = train\n",
    "\n",
    "print (\"Rows: \" + str(train.shape[0]) + \", Columns: \" + str(train.shape[1]))\n",
    "print(train.head())\n",
    "\n",
    "test = pd.read_csv('data/test_cleaned.csv')\n",
    "#test_X = test.drop([\"ID\"], axis=1)\n",
    "print (\"Rows: \" + str(test.shape[0]) + \", Columns: \" + str(test.shape[1]))\n",
    "test_X = test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4459 entries, 0 to 4458\n",
      "Columns: 1420 entries, SumValues to geometric_mean\n",
      "dtypes: float64(1416), int64(4)\n",
      "memory usage: 48.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49342 entries, 0 to 49341\n",
      "Columns: 1420 entries, SumValues to geometric_mean\n",
      "dtypes: float64(1416), int64(4)\n",
      "memory usage: 534.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 17.45309674,  13.3046866 ,  16.11809575, ...,  14.84513033,\n",
       "        16.11809575,  16.81124288])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info()\n",
    "test_X.info()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Features with NaN Values = 0\n"
     ]
    }
   ],
   "source": [
    "#### Check if there are any NULL values in Train Data\n",
    "print(\"Total Train Features with NaN Values = \" + str(X_train.columns[X_train.isnull().sum() != 0].size))\n",
    "if (X_train.columns[X_train.isnull().sum() != 0].size):\n",
    "    print(\"Features with NaN => {}\".format(list(X_train.columns[X_train.isnull().sum() != 0])))\n",
    "    X_train[X_train.columns[X_train.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize and scale the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "\n",
    "#minMax_train = MinMaxScaler().fit_transform(X_train.values)\n",
    "#standardScaler_train = StandardScaler().fit_transform(X_train.values)\n",
    "#robustScaler_train = RobustScaler().fit_transform(X_train.values)\n",
    "#maxAbsScaler_train = MaxAbsScaler().fit_transform(X_train.values)\n",
    "\n",
    "\n",
    "#minMax_test = MinMaxScaler().fit_transform(test_X.values)\n",
    "#standardScaler_test = StandardScaler().fit_transform(test_X.values)\n",
    "#robustScaler_test = RobustScaler().fit_transform(test_X.values)\n",
    "#maxAbsScaler_test = MaxAbsScaler().fit_transform(test_X.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : 'rmse',\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42,\n",
    "        \"n_threads\": -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgtrain, lgval],\n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    #pred_test_y = inv_boxcox(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unknown type of parameter:feval, got:function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b875ac421666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#pred_test_maxAbsScaler_lgbm, model_maxAbsScaler_lgbm, evals_result_maxAbsScaler_lgbm = lgbm_auto(maxAbsScaler_train, y_train, maxAbsScaler_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vanilla\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpred_test_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals_result_lgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm_auto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d8824580ca5a>\u001b[0m in \u001b[0;36mlgbm_auto\u001b[0;34m(data, y_train, test_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                       evals_result=evals_result)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training data should be Dataset instance, met {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mparam_dict_to_str\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             raise TypeError('Unknown type of parameter:%s, got:%s'\n\u001b[0;32m--> 136\u001b[0;31m                             % (key, type(val).__name__))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unknown type of parameter:feval, got:function"
     ]
    }
   ],
   "source": [
    "'''print(\"baseline\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, test_X)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"minMAx\")\n",
    "pred_test_minMax_lgbm, model_minMax_lgbm, evals_result_minMax_lgbm = lgbm_auto(minMax_train, y_train, minMax_test)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"standardScaler\")\n",
    "pred_test_standardScaler_lgbm, model_standardScaler_lgbm, evals_result_standardScaler_lgbm = lgbm_auto(standardScaler_train, y_train, standardScaler_test)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"robustScaler\")\n",
    "pred_test_robustScaler_lgbm, model_robustScaler_lgbm, evals_result_robustScaler_lgbm = lgbm_auto(robustScaler_train, y_train, robustScaler_test)\n",
    "print(\"----------------------------------------------\")'''\n",
    "#print(\"maxAbsScaler\")\n",
    "#pred_test_maxAbsScaler_lgbm, model_maxAbsScaler_lgbm, evals_result_maxAbsScaler_lgbm = lgbm_auto(maxAbsScaler_train, y_train, maxAbsScaler_test)\n",
    "print(\"vanilla\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# feature importance\n",
    "print(\"Features Importance model_minMax...\")\n",
    "gain = model_minMax_lgbm.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model_minMax_lgbm.feature_name(), \n",
    "                   'split':model_minMax_lgbm.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:15])\n",
    "\n",
    "# feature importance\n",
    "print(\"Features Importance model_standardScaler...\")\n",
    "gain = model_standardScaler_lgbm.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model_standardScaler_lgbm.feature_name(), \n",
    "                   'split':model_standardScaler_lgbm.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:15])\n",
    "\n",
    "# feature importance\n",
    "print(\"Features Importance model_robustScaler...\")\n",
    "gain = model_robustScaler_lgbm.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model_robustScaler_lgbm.feature_name(), \n",
    "                   'split':model_robustScaler_lgbm.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:15])'''\n",
    "\n",
    "# feature importance\n",
    "print(\"Features Importance model_maxAbsScaler...\")\n",
    "gain = model_lgbm.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature':model_lgbm.feature_name(), \n",
    "                   'split':model_lgbm.feature_importance('split'), \n",
    "                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {'objective': 'reg:linear', \n",
    "          'eval_metric': 'rmse',\n",
    "          'eta': 0.001,\n",
    "          'max_depth': 10, \n",
    "          'subsample': 0.6, \n",
    "          'colsample_bytree': 0.6,\n",
    "          'alpha':0.001,\n",
    "          'random_state': 42, \n",
    "          'silent': True}\n",
    "    \n",
    "    tr_data = xgb.DMatrix(train_X, train_y)\n",
    "    va_data = xgb.DMatrix(val_X, val_y)\n",
    "    \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(params, tr_data, 3500, watchlist, maximize=False, early_stopping_rounds = 100, verbose_eval=50)\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_data)\n",
    "    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n",
    "    \n",
    "    return xgb_pred_y, model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"minMAx\")\n",
    "#pred_test_minMax_xgb, model_minMax_xgb = xgb_auto(minMax_train, y_train, minMax_test))\n",
    "#print(\"----------------------------------------------\")\n",
    "#print(\"standardScaler\")\n",
    "#pred_test_standardScaler_xgb, model_standardScaler_xgb = xgb_auto(standardScaler_train, y_train, standardScaler_test)\n",
    "#print(\"----------------------------------------------\")\n",
    "#print(\"robustScaler\")\n",
    "#pred_test_robustScaler_xgb, model_robustScaler_xgb = xgb_auto(robustScaler_train, y_train, robustScaler_test)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"maxAbsScaler\")\n",
    "pred_test_maxAbsScaler_xgb, model_maxAbsScaler_xgb = xgb_auto(maxAbsScaler_train, y_train, maxAbsScaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    cb_model = CatBoostRegressor(iterations=500,\n",
    "                             learning_rate=0.05,\n",
    "                             depth=10,\n",
    "                             eval_metric='RMSE',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 20,\n",
    "                             od_wait=20)\n",
    "    \n",
    "    cb_model.fit(train_X, train_y,\n",
    "             eval_set=(val_X, val_y),\n",
    "             use_best_model=True,\n",
    "             verbose=True)\n",
    "    \n",
    "    pred_test_cat = np.expm1(cb_model.predict(test_data))\n",
    "    \n",
    "    return pred_test_cat, cb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(\"minMax\")\n",
    "pred_test_minMax_cat, model_minMax_cat = cat_auto(minMax_train, y_train, minMax_test)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"standardScaler\")\n",
    "pred_test_standardScaler_cat, model_standardScaler_cat = cat_auto(standardScaler_train, y_train, standardScaler_Test)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"robustScaler\")\n",
    "pred_test_robustScaler_cat, model_robustScaler_cat = cat_auto(robustScaler_train, y_train, robustScaler_test)\n",
    "print(\"----------------------------------------------\")'''\n",
    "print(\"maxAbsScaler\")\n",
    "pred_test_maxAbsScaler_cat, model_maxAbsScaler_cat = cat_auto(maxAbsScaler_train, y_train, maxAbsScaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM predictions\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test_lgbm\n",
    "\n",
    "sub[\"target\"] = sub_lgb[\"target\"] \n",
    "\n",
    "print(sub.head())\n",
    "sub.to_csv('submit/sub_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test_maxAbsScaler_lgbm\n",
    "\n",
    "sub_xgb = pd.DataFrame()\n",
    "sub_xgb[\"target\"] = pred_test_maxAbsScaler_xgb\n",
    "\n",
    "sub_cat = pd.DataFrame()\n",
    "sub_cat[\"target\"] = pred_test_maxAbsScaler_cat\n",
    "\n",
    "sub[\"target\"] = (sub_lgb[\"target\"] + sub_xgb[\"target\"] + sub_cat[\"target\"])/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub.head())\n",
    "sub.to_csv('submit/sub_lgb_xgb_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

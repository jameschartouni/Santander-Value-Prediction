{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#James Chartouni\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, normalize, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, MeanShift, DBSCAN, Birch, SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lgbm_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42,\n",
    "        \"n_threads\":-1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4459, Columns: 1416\n",
      "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  0d866c3d7  bd8f989f1  \\\n",
      "0        103      4628        0.0        0.0          0        0.0        0.0   \n",
      "1         68      4663  2200000.0        0.0          0        0.0        0.0   \n",
      "2         19      4712        0.0        0.0          0        0.0        0.0   \n",
      "3         23      4708        0.0        0.0          0        0.0        0.0   \n",
      "4         27      4704  2000000.0        0.0          0        0.0        0.0   \n",
      "\n",
      "   22ed6dba3  92b13ebba  233c7c17c      ...                Mean         Max  \\\n",
      "0        0.0        0.0        0.0      ...       152382.311484  40000000.0   \n",
      "1        0.0        0.0        0.0      ...       112466.525725  50000000.0   \n",
      "2        0.0        0.0        0.0      ...        16109.936575  12000000.0   \n",
      "3        0.0        0.0        0.0      ...         7059.337560   6000000.0   \n",
      "4        0.0        0.0        0.0      ...        37778.858351  37662000.0   \n",
      "\n",
      "            Var           Std  Q4.95          Q5       Skew            mad  \\\n",
      "0  3.198114e+12  1.788327e+06    0.0  40000000.0  16.447229  298192.531733   \n",
      "1  2.467155e+12  1.570718e+06    0.0  50000000.0  21.646817  221746.896176   \n",
      "2  1.158791e+11  3.404102e+05    0.0  12000000.0  26.463772   32097.260525   \n",
      "3  3.187070e+10  1.785237e+05    0.0   6000000.0  30.479705   14055.146119   \n",
      "4  7.592118e+11  8.713276e+05    0.0  37662000.0  36.106175   75142.388872   \n",
      "\n",
      "          kurt           sem  \n",
      "0   304.618388  26002.577147  \n",
      "1   559.984067  22838.505209  \n",
      "2   793.649934   4949.622182  \n",
      "3   972.600954   2595.763960  \n",
      "4  1490.758865  12669.249827  \n",
      "\n",
      "[5 rows x 1416 columns]\n",
      "Rows: 49342, Columns: 1416\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned.csv\")\n",
    "train_orig = pd.read_csv(\"data/train.csv\")\n",
    "y_train = np.log1p(train_orig[\"target\"].values)\n",
    "X_train = train\n",
    "#X_train = train.drop([\"target\", \"ID\"], axis=1)\n",
    "\n",
    "print (\"Rows: \" + str(train.shape[0]) + \", Columns: \" + str(train.shape[1]))\n",
    "print(train.head())\n",
    "\n",
    "test = pd.read_csv('data/test_cleaned.csv')\n",
    "#X_test = test.drop([\"ID\"], axis=1)\n",
    "print (\"Rows: \" + str(test.shape[0]) + \", Columns: \" + str(test.shape[1]))\n",
    "X_test = test\n",
    "\n",
    "\n",
    "#consolidate data before clustering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.5913\n",
      "[100]\tvalid_0's rmse: 1.51809\n",
      "[150]\tvalid_0's rmse: 1.46916\n",
      "[200]\tvalid_0's rmse: 1.43673\n",
      "[250]\tvalid_0's rmse: 1.41455\n",
      "[300]\tvalid_0's rmse: 1.39998\n",
      "[350]\tvalid_0's rmse: 1.38966\n",
      "[400]\tvalid_0's rmse: 1.3824\n",
      "[450]\tvalid_0's rmse: 1.37831\n",
      "[500]\tvalid_0's rmse: 1.37556\n",
      "[550]\tvalid_0's rmse: 1.37307\n",
      "[600]\tvalid_0's rmse: 1.37128\n",
      "[650]\tvalid_0's rmse: 1.37105\n",
      "[700]\tvalid_0's rmse: 1.37119\n",
      "Early stopping, best iteration is:\n",
      "[646]\tvalid_0's rmse: 1.37093\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 4 0 0]\n",
      "[0 0 0 ..., 5 0 0]\n",
      "[0 0 0 ..., 4 0 0]\n",
      "[0 0 0 ..., 6 0 0]\n",
      "[0 0 0 ..., 5 0 0]\n",
      "[2 2 2 ..., 0 2 2]\n",
      "['kmeans_cluster_2', 'kmeans_cluster_3', 'kmeans_cluster_4', 'kmeans_cluster_5', 'kmeans_cluster_6', 'kmeans_cluster_7', 'kmeans_cluster_8', 'kmeans_cluster_9', 'kmeans_cluster_10']\n"
     ]
    }
   ],
   "source": [
    "flist = [x for x in X_train.columns if not x in ['ID','target']]\n",
    "\n",
    "flist_kmeans = []\n",
    "for ncl in range(2,11):#change this to change how many clusters \n",
    "    cls = KMeans(n_clusters=ncl)\n",
    "    cls.fit_predict(X_train[flist].values)\n",
    "    print(cls.predict(X_train[flist].values))\n",
    "    X_train['kmeans_cluster_'+str(ncl)] = cls.predict(X_train[flist].values)\n",
    "    X_test['kmeans_cluster_'+str(ncl)] = cls.predict(X_test[flist].values)\n",
    "    flist_kmeans.append('kmeans_cluster_'+str(ncl))\n",
    "print(flist_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#one hot encode clustered varaibles\\nX_train = label_binarizer(X_train, flist_kmeans)\\nX_train = X_train.drop(flist_kmeans, axis=1)\\n\\nX_test = label_binarizer(X_test, flist_kmeans)\\nX_test = X_test.drop(flist_kmeans, axis=1)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encode clustered varaibles\n",
    "X_train = label_binarizer(X_train, flist_kmeans)\n",
    "X_train = X_train.drop(flist_kmeans, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, flist_kmeans)\n",
    "X_test = X_test.drop(flist_kmeans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1425)\n",
      "Test set size: (49342, 1425)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59022\n",
      "[100]\tvalid_0's rmse: 1.51873\n",
      "[150]\tvalid_0's rmse: 1.46965\n",
      "[200]\tvalid_0's rmse: 1.43711\n",
      "[250]\tvalid_0's rmse: 1.41457\n",
      "[300]\tvalid_0's rmse: 1.39971\n",
      "[350]\tvalid_0's rmse: 1.3904\n",
      "[400]\tvalid_0's rmse: 1.38259\n",
      "[450]\tvalid_0's rmse: 1.3788\n",
      "[500]\tvalid_0's rmse: 1.37594\n",
      "[550]\tvalid_0's rmse: 1.37471\n",
      "[600]\tvalid_0's rmse: 1.37359\n",
      "[650]\tvalid_0's rmse: 1.37281\n",
      "[700]\tvalid_0's rmse: 1.37193\n",
      "[750]\tvalid_0's rmse: 1.37198\n",
      "[800]\tvalid_0's rmse: 1.37137\n",
      "[850]\tvalid_0's rmse: 1.37115\n",
      "[900]\tvalid_0's rmse: 1.37153\n",
      "[950]\tvalid_0's rmse: 1.3717\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid_0's rmse: 1.37115\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ kmeans\") #1.3707\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4457\n"
     ]
    }
   ],
   "source": [
    "# Compute Affinity Propagation\n",
    "af = AffinityPropagation(preference=-50).fit(X_train[flist].values)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "X_train['AfinityProp'] = af.predict(X_train[flist].values)\n",
    "X_test['AfinityProp'] = af.predict(X_test[flist].values)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ affinity \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.5898\n",
      "[100]\tvalid_0's rmse: 1.51796\n",
      "[150]\tvalid_0's rmse: 1.46856\n",
      "[200]\tvalid_0's rmse: 1.43597\n",
      "[250]\tvalid_0's rmse: 1.41387\n",
      "[300]\tvalid_0's rmse: 1.39813\n",
      "[350]\tvalid_0's rmse: 1.38673\n",
      "[400]\tvalid_0's rmse: 1.37921\n",
      "[450]\tvalid_0's rmse: 1.37513\n",
      "[500]\tvalid_0's rmse: 1.37202\n",
      "[550]\tvalid_0's rmse: 1.36955\n",
      "[600]\tvalid_0's rmse: 1.36867\n",
      "[650]\tvalid_0's rmse: 1.36804\n",
      "[700]\tvalid_0's rmse: 1.36803\n",
      "[750]\tvalid_0's rmse: 1.36777\n",
      "[800]\tvalid_0's rmse: 1.3676\n",
      "[850]\tvalid_0's rmse: 1.36803\n",
      "Early stopping, best iteration is:\n",
      "[786]\tvalid_0's rmse: 1.36748\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ affinity \")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "number of estimated clusters : 8\n"
     ]
    }
   ],
   "source": [
    "#means-shift\n",
    "from sklearn import cluster\n",
    "\n",
    "bandwidth = cluster.estimate_bandwidth(X_train, quantile=.3, n_jobs=-1) #adjust here \n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "\n",
    "print(ms.fit_predict(X_train[flist].values))\n",
    "X_train['meanshift'] = ms.predict(X_train[flist].values)\n",
    "X_test['meanshift'] = ms.predict(X_test[flist].values)\n",
    "\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ meanshift\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59129\n",
      "[100]\tvalid_0's rmse: 1.51934\n",
      "[150]\tvalid_0's rmse: 1.47086\n",
      "[200]\tvalid_0's rmse: 1.43767\n",
      "[250]\tvalid_0's rmse: 1.41486\n",
      "[300]\tvalid_0's rmse: 1.39931\n",
      "[350]\tvalid_0's rmse: 1.38907\n",
      "[400]\tvalid_0's rmse: 1.38155\n",
      "[450]\tvalid_0's rmse: 1.37615\n",
      "[500]\tvalid_0's rmse: 1.37274\n",
      "[550]\tvalid_0's rmse: 1.37022\n",
      "[600]\tvalid_0's rmse: 1.36968\n",
      "[650]\tvalid_0's rmse: 1.36899\n",
      "[700]\tvalid_0's rmse: 1.36915\n",
      "[750]\tvalid_0's rmse: 1.36879\n",
      "[800]\tvalid_0's rmse: 1.36855\n",
      "[850]\tvalid_0's rmse: 1.36823\n",
      "[900]\tvalid_0's rmse: 1.36869\n",
      "Early stopping, best iteration is:\n",
      "[820]\tvalid_0's rmse: 1.36808\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ meanshift\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1471)\n",
      "Test set size: (49342, 1471)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"meanshift\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1478)\n",
      "Test set size: (49342, 1478)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ one hot encode\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59466\n",
      "[100]\tvalid_0's rmse: 1.52269\n",
      "[150]\tvalid_0's rmse: 1.47546\n",
      "[200]\tvalid_0's rmse: 1.44197\n",
      "[250]\tvalid_0's rmse: 1.41836\n",
      "[300]\tvalid_0's rmse: 1.40325\n",
      "[350]\tvalid_0's rmse: 1.39365\n",
      "[400]\tvalid_0's rmse: 1.38653\n",
      "[450]\tvalid_0's rmse: 1.38209\n",
      "[500]\tvalid_0's rmse: 1.37968\n",
      "[550]\tvalid_0's rmse: 1.3772\n",
      "[600]\tvalid_0's rmse: 1.37613\n",
      "[650]\tvalid_0's rmse: 1.37552\n",
      "[700]\tvalid_0's rmse: 1.37445\n",
      "[750]\tvalid_0's rmse: 1.37422\n",
      "[800]\tvalid_0's rmse: 1.37424\n",
      "[850]\tvalid_0's rmse: 1.37432\n",
      "Early stopping, best iteration is:\n",
      "[770]\tvalid_0's rmse: 1.37399\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ one hot encode\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Birch\n",
    "birch = Birch(n_clusters=10)\n",
    "birch.fit_predict(X_train[flist].values)\n",
    "X_train['birch'] = birch.predict(X_train[flist].values)\n",
    "X_test['birch'] = birch.predict(X_test[flist].values)\n",
    "\n",
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"birch\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1488)\n",
      "Test set size: (49342, 1488)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ birch\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59269\n",
      "[100]\tvalid_0's rmse: 1.52151\n",
      "[150]\tvalid_0's rmse: 1.47268\n",
      "[200]\tvalid_0's rmse: 1.43928\n",
      "[250]\tvalid_0's rmse: 1.41583\n",
      "[300]\tvalid_0's rmse: 1.39998\n",
      "[350]\tvalid_0's rmse: 1.3899\n",
      "[400]\tvalid_0's rmse: 1.38237\n",
      "[450]\tvalid_0's rmse: 1.37808\n",
      "[500]\tvalid_0's rmse: 1.37522\n",
      "[550]\tvalid_0's rmse: 1.37224\n",
      "[600]\tvalid_0's rmse: 1.37111\n",
      "[650]\tvalid_0's rmse: 1.37023\n",
      "[700]\tvalid_0's rmse: 1.37022\n",
      "[750]\tvalid_0's rmse: 1.36988\n",
      "[800]\tvalid_0's rmse: 1.36986\n",
      "[850]\tvalid_0's rmse: 1.36979\n",
      "Early stopping, best iteration is:\n",
      "[763]\tvalid_0's rmse: 1.36949\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ birch\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID        target\n",
      "0  000137c73  2.604974e+06\n",
      "1  00021489f  2.177407e+06\n",
      "2  0004d7953  2.515046e+06\n",
      "3  00056a333  4.243339e+06\n",
      "4  00056d8eb  1.630270e+06\n"
     ]
    }
   ],
   "source": [
    "#LGBM predictions\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test_lgbm\n",
    "\n",
    "sub[\"target\"] = sub_lgb[\"target\"] \n",
    "\n",
    "print(sub.head())\n",
    "sub.to_csv('submit/sub_lgb_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/train_clustered.csv\", index=False)\n",
    "X_test.to_csv('data/test_clustered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

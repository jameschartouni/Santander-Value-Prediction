{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#James Chartouni\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, normalize, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, MeanShift, DBSCAN, Birch, SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lgbm_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4459, Columns: 4993\n",
      "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
      "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
      "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
      "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
      "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
      "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
      "\n",
      "   2f0771a37  30347e683  d08d1fbe3  6ee66e115    ...      3ecc09859  \\\n",
      "0          0          0          0          0    ...            0.0   \n",
      "1          0          0          0          0    ...            0.0   \n",
      "2          0          0          0          0    ...            0.0   \n",
      "3          0          0          0          0    ...            0.0   \n",
      "4          0          0          0          0    ...            0.0   \n",
      "\n",
      "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
      "0        0.0        0.0          0          0          0          0   \n",
      "1        0.0        0.0          0          0          0          0   \n",
      "2        0.0        0.0          0          0          0          0   \n",
      "3        0.0        0.0          0          0          0          0   \n",
      "4        0.0        0.0          0          0          0          0   \n",
      "\n",
      "   fb36b89d9  7e293fbaf  9fc776466  \n",
      "0          0          0          0  \n",
      "1          0          0          0  \n",
      "2          0          0          0  \n",
      "3          0          0          0  \n",
      "4          0          0          0  \n",
      "\n",
      "[5 rows x 4993 columns]\n",
      "Rows: 49342, Columns: 4992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010    ...      3ecc09859  \\\n",
       "0        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "1        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "2        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "3        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "4        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned.csv\")\n",
    "y_train = train['target'] #TRY A LOG TRANSFORM\n",
    "y_train = np.log1p(train[\"target\"].values)\n",
    "X_train = train.drop([\"target\", \"ID\"], axis=1)\n",
    "\n",
    "print (\"Rows: \" + str(train.shape[0]) + \", Columns: \" + str(train.shape[1]))\n",
    "print(train.head())\n",
    "\n",
    "test = pd.read_csv('data/test_cleaned.csv')\n",
    "X_test = test.drop([\"ID\"], axis=1)\n",
    "print (\"Rows: \" + str(test.shape[0]) + \", Columns: \" + str(test.shape[1]))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61613\n",
      "[100]\tvalid_0's rmse: 1.55793\n",
      "[150]\tvalid_0's rmse: 1.51496\n",
      "[200]\tvalid_0's rmse: 1.48384\n",
      "[250]\tvalid_0's rmse: 1.46215\n",
      "[300]\tvalid_0's rmse: 1.44614\n",
      "[350]\tvalid_0's rmse: 1.4358\n",
      "[400]\tvalid_0's rmse: 1.42738\n",
      "[450]\tvalid_0's rmse: 1.42235\n",
      "[500]\tvalid_0's rmse: 1.41816\n",
      "[550]\tvalid_0's rmse: 1.4155\n",
      "[600]\tvalid_0's rmse: 1.4136\n",
      "[650]\tvalid_0's rmse: 1.4119\n",
      "[700]\tvalid_0's rmse: 1.41163\n",
      "[750]\tvalid_0's rmse: 1.4113\n",
      "[800]\tvalid_0's rmse: 1.41097\n",
      "[850]\tvalid_0's rmse: 1.41103\n",
      "[900]\tvalid_0's rmse: 1.4108\n",
      "[950]\tvalid_0's rmse: 1.41131\n",
      "[1000]\tvalid_0's rmse: 1.41175\n",
      "Early stopping, best iteration is:\n",
      "[908]\tvalid_0's rmse: 1.41069\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[3 3 3 ..., 3 3 3]\n",
      "['kmeans_cluster_2', 'kmeans_cluster_3', 'kmeans_cluster_4', 'kmeans_cluster_5', 'kmeans_cluster_6', 'kmeans_cluster_7', 'kmeans_cluster_8', 'kmeans_cluster_9', 'kmeans_cluster_10']\n"
     ]
    }
   ],
   "source": [
    "flist = [x for x in X_train.columns if not x in ['ID','target']]\n",
    "\n",
    "flist_kmeans = []\n",
    "for ncl in range(2,11):#change this to change how many clusters \n",
    "    cls = KMeans(n_clusters=ncl)\n",
    "    cls.fit_predict(X_train[flist].values)\n",
    "    print(cls.predict(X_train[flist].values))\n",
    "    X_train['kmeans_cluster_'+str(ncl)] = cls.predict(X_train[flist].values)\n",
    "    X_test['kmeans_cluster_'+str(ncl)] = cls.predict(X_test[flist].values)\n",
    "    flist_kmeans.append('kmeans_cluster_'+str(ncl))\n",
    "print(flist_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 5000)\n",
      "Test set size: (49342, 5000)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61695\n",
      "[100]\tvalid_0's rmse: 1.55722\n",
      "[150]\tvalid_0's rmse: 1.51417\n",
      "[200]\tvalid_0's rmse: 1.48357\n",
      "[250]\tvalid_0's rmse: 1.46176\n",
      "[300]\tvalid_0's rmse: 1.44649\n",
      "[350]\tvalid_0's rmse: 1.43531\n",
      "[400]\tvalid_0's rmse: 1.42694\n",
      "[450]\tvalid_0's rmse: 1.42107\n",
      "[500]\tvalid_0's rmse: 1.41726\n",
      "[550]\tvalid_0's rmse: 1.41401\n",
      "[600]\tvalid_0's rmse: 1.41199\n",
      "[650]\tvalid_0's rmse: 1.41083\n",
      "[700]\tvalid_0's rmse: 1.41006\n",
      "[750]\tvalid_0's rmse: 1.41\n",
      "[800]\tvalid_0's rmse: 1.41018\n",
      "Early stopping, best iteration is:\n",
      "[716]\tvalid_0's rmse: 1.40961\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ kmeans\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4458\n"
     ]
    }
   ],
   "source": [
    "# Compute Affinity Propagation\n",
    "af = AffinityPropagation(preference=-50).fit(X_train[flist].values)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "X_train['AfinityProp'] = af.predict(X_train[flist].values)\n",
    "X_test['AfinityProp'] = af.predict(X_test[flist].values)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ affinity \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61602\n",
      "[100]\tvalid_0's rmse: 1.5565\n",
      "[150]\tvalid_0's rmse: 1.515\n",
      "[200]\tvalid_0's rmse: 1.48294\n",
      "[250]\tvalid_0's rmse: 1.4595\n",
      "[300]\tvalid_0's rmse: 1.44423\n",
      "[350]\tvalid_0's rmse: 1.43382\n",
      "[400]\tvalid_0's rmse: 1.42543\n",
      "[450]\tvalid_0's rmse: 1.42003\n",
      "[500]\tvalid_0's rmse: 1.41528\n",
      "[550]\tvalid_0's rmse: 1.41248\n",
      "[600]\tvalid_0's rmse: 1.41022\n",
      "[650]\tvalid_0's rmse: 1.40916\n",
      "[700]\tvalid_0's rmse: 1.40913\n",
      "[750]\tvalid_0's rmse: 1.40929\n",
      "Early stopping, best iteration is:\n",
      "[675]\tvalid_0's rmse: 1.40888\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ affinity \")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "number of estimated clusters : 199\n"
     ]
    }
   ],
   "source": [
    "#means-shift\n",
    "from sklearn import cluster\n",
    "\n",
    "bandwidth = cluster.estimate_bandwidth(X_train, quantile=.3, n_jobs=-1) #adjust here \n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "\n",
    "print(ms.fit_predict(X_train[flist].values))\n",
    "X_train['meanshift'] = ms.predict(X_train[flist].values)\n",
    "X_test['meanshift'] = ms.predict(X_test[flist].values)\n",
    "\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ meanshift\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61571\n",
      "[100]\tvalid_0's rmse: 1.55643\n",
      "[150]\tvalid_0's rmse: 1.51311\n",
      "[200]\tvalid_0's rmse: 1.48201\n",
      "[250]\tvalid_0's rmse: 1.45949\n",
      "[300]\tvalid_0's rmse: 1.44373\n",
      "[350]\tvalid_0's rmse: 1.43285\n",
      "[400]\tvalid_0's rmse: 1.42485\n",
      "[450]\tvalid_0's rmse: 1.42008\n",
      "[500]\tvalid_0's rmse: 1.4164\n",
      "[550]\tvalid_0's rmse: 1.414\n",
      "[600]\tvalid_0's rmse: 1.41177\n",
      "[650]\tvalid_0's rmse: 1.4105\n",
      "[700]\tvalid_0's rmse: 1.40989\n",
      "[750]\tvalid_0's rmse: 1.41002\n",
      "[800]\tvalid_0's rmse: 1.41012\n",
      "Early stopping, best iteration is:\n",
      "[710]\tvalid_0's rmse: 1.40978\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ meanshift\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 5002)\n",
      "Test set size: (49342, 5002)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"meanshift\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 5200)\n",
      "Test set size: (49342, 5151)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ one hot encode\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61565\n",
      "[100]\tvalid_0's rmse: 1.55841\n",
      "[150]\tvalid_0's rmse: 1.51603\n",
      "[200]\tvalid_0's rmse: 1.4843\n",
      "[250]\tvalid_0's rmse: 1.46176\n",
      "[300]\tvalid_0's rmse: 1.44537\n",
      "[350]\tvalid_0's rmse: 1.43439\n",
      "[400]\tvalid_0's rmse: 1.42656\n",
      "[450]\tvalid_0's rmse: 1.42077\n",
      "[500]\tvalid_0's rmse: 1.41689\n",
      "[550]\tvalid_0's rmse: 1.41411\n",
      "[600]\tvalid_0's rmse: 1.41206\n",
      "[650]\tvalid_0's rmse: 1.41118\n",
      "[700]\tvalid_0's rmse: 1.41083\n",
      "[750]\tvalid_0's rmse: 1.41024\n",
      "[800]\tvalid_0's rmse: 1.41029\n",
      "[850]\tvalid_0's rmse: 1.41047\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's rmse: 1.41014\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ one hot encode\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Birch\n",
    "birch = Birch(n_clusters=10)\n",
    "birch.fit_predict(X_train[flist].values)\n",
    "X_train['birch'] = birch.predict(X_train[flist].values)\n",
    "X_test['birch'] = birch.predict(X_test[flist].values)\n",
    "\n",
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"birch\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 5210)\n",
      "Test set size: (49342, 5152)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ birch\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.61565\n",
      "[100]\tvalid_0's rmse: 1.55841\n",
      "[150]\tvalid_0's rmse: 1.51603\n",
      "[200]\tvalid_0's rmse: 1.4843\n",
      "[250]\tvalid_0's rmse: 1.46176\n",
      "[300]\tvalid_0's rmse: 1.44537\n",
      "[350]\tvalid_0's rmse: 1.43439\n",
      "[400]\tvalid_0's rmse: 1.42656\n",
      "[450]\tvalid_0's rmse: 1.42077\n",
      "[500]\tvalid_0's rmse: 1.41689\n",
      "[550]\tvalid_0's rmse: 1.41411\n",
      "[600]\tvalid_0's rmse: 1.41206\n",
      "[650]\tvalid_0's rmse: 1.41118\n",
      "[700]\tvalid_0's rmse: 1.41083\n",
      "[750]\tvalid_0's rmse: 1.41024\n",
      "[800]\tvalid_0's rmse: 1.41029\n",
      "[850]\tvalid_0's rmse: 1.41047\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's rmse: 1.41014\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ birch\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/train_clustered.csv\", index=False)\n",
    "X_test.to_csv('data/test_clustered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

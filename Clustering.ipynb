{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#James Chartouni\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, normalize, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, MeanShift, DBSCAN, Birch, SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lgbm_auto(data, y_train, test_data):\n",
    "      \n",
    "    train_X, val_X, train_y, val_y = train_test_split(data, y_train, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42,\n",
    "        \"n_threads\":-1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_data, num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4459, Columns: 1420\n",
      "   SumValues  SumZeros  20aa07010  dc5a8f1d8  4681de4fd  adf119b9a  0d866c3d7  \\\n",
      "0        103      4628   0.000000        0.0        0.0        0.0        0.0   \n",
      "1         68      4663  14.603968        0.0        0.0        0.0        0.0   \n",
      "2         19      4712   0.000000        0.0        0.0        0.0        0.0   \n",
      "3         23      4708   0.000000        0.0        0.0        0.0        0.0   \n",
      "4         27      4704  14.508658        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   bd8f989f1  22ed6dba3  92b13ebba       ...             Std  Q4.95  \\\n",
      "0        0.0        0.0        0.0       ...        2.169096    0.0   \n",
      "1        0.0        0.0        0.0       ...        1.809385    0.0   \n",
      "2        0.0        0.0        0.0       ...        0.909701    0.0   \n",
      "3        0.0        0.0        0.0       ...        0.887781    0.0   \n",
      "4        0.0        0.0        0.0       ...        1.098374    0.0   \n",
      "\n",
      "          Q5       Skew       mad        kurt       sem  number_of_different  \\\n",
      "0  17.504390   6.680490  0.627328   43.068786  0.031539                   63   \n",
      "1  17.727534   8.285303  0.426605   67.033615  0.026309                   33   \n",
      "2  16.300417  16.285642  0.111617  264.921101  0.013227                   22   \n",
      "3  15.607270  15.013488  0.119476  227.401614  0.012908                   23   \n",
      "4  17.444162  13.627510  0.161356  185.763814  0.015971                   25   \n",
      "\n",
      "   non_zero_count  geometric_mean  \n",
      "0             115       14.975334  \n",
      "1              80       14.998494  \n",
      "2              31       11.806805  \n",
      "3              35       11.124137  \n",
      "4              39       12.893002  \n",
      "\n",
      "[5 rows x 1420 columns]\n",
      "Rows: 49342, Columns: 1420\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned.csv\")\n",
    "train_orig = pd.read_csv(\"data/train.csv\")\n",
    "y_train = np.log1p(train_orig[\"target\"].values)\n",
    "X_train = train\n",
    "#X_train = train.drop([\"target\", \"ID\"], axis=1)\n",
    "\n",
    "print (\"Rows: \" + str(train.shape[0]) + \", Columns: \" + str(train.shape[1]))\n",
    "print(train.head())\n",
    "\n",
    "test = pd.read_csv('data/test_cleaned.csv')\n",
    "#X_test = test.drop([\"ID\"], axis=1)\n",
    "print (\"Rows: \" + str(test.shape[0]) + \", Columns: \" + str(test.shape[1]))\n",
    "X_test = test\n",
    "\n",
    "\n",
    "#consolidate data before clustering \n",
    "alldata = pd.concat([train,test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.58307\n",
      "[100]\tvalid_0's rmse: 1.50778\n",
      "[150]\tvalid_0's rmse: 1.45739\n",
      "[200]\tvalid_0's rmse: 1.42346\n",
      "[250]\tvalid_0's rmse: 1.39933\n",
      "[300]\tvalid_0's rmse: 1.38547\n",
      "[350]\tvalid_0's rmse: 1.37519\n",
      "[400]\tvalid_0's rmse: 1.36744\n",
      "[450]\tvalid_0's rmse: 1.36306\n",
      "[500]\tvalid_0's rmse: 1.36047\n",
      "[550]\tvalid_0's rmse: 1.35913\n",
      "[600]\tvalid_0's rmse: 1.35845\n",
      "[650]\tvalid_0's rmse: 1.35798\n",
      "[700]\tvalid_0's rmse: 1.35803\n",
      "Early stopping, best iteration is:\n",
      "[632]\tvalid_0's rmse: 1.35784\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kmeans_cluster_2', 'kmeans_cluster_3', 'kmeans_cluster_4', 'kmeans_cluster_5', 'kmeans_cluster_6', 'kmeans_cluster_7', 'kmeans_cluster_8', 'kmeans_cluster_9', 'kmeans_cluster_10']\n"
     ]
    }
   ],
   "source": [
    "flist = [x for x in X_train.columns if not x in ['ID','target']]\n",
    "\n",
    "flist_kmeans = []\n",
    "for ncl in range(2,11):#change this to change how many clusters \n",
    "    print(ncl)\n",
    "    cls = KMeans(n_clusters=ncl)\n",
    "    cls.fit_predict(alldata[flist].values)\n",
    "    X_train['kmeans_cluster_'+str(ncl)] = cls.predict(X_train[flist].values)\n",
    "    X_test['kmeans_cluster_'+str(ncl)] = cls.predict(X_test[flist].values)\n",
    "    alldata['kmeans_cluster_'+str(ncl)] = cls.predict(alldata[flist].values)\n",
    "    flist_kmeans.append('kmeans_cluster_'+str(ncl))\n",
    "print(flist_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode clustered varaibles\n",
    "X_train = label_binarizer(X_train, flist_kmeans)\n",
    "X_train = X_train.drop(flist_kmeans, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, flist_kmeans)\n",
    "X_test = X_test.drop(flist_kmeans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1473)\n",
      "Test set size: (49342, 1473)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.58359\n",
      "[100]\tvalid_0's rmse: 1.50859\n",
      "[150]\tvalid_0's rmse: 1.45933\n",
      "[200]\tvalid_0's rmse: 1.42484\n",
      "[250]\tvalid_0's rmse: 1.40153\n",
      "[300]\tvalid_0's rmse: 1.38598\n",
      "[350]\tvalid_0's rmse: 1.37503\n",
      "[400]\tvalid_0's rmse: 1.36778\n",
      "[450]\tvalid_0's rmse: 1.36376\n",
      "[500]\tvalid_0's rmse: 1.36159\n",
      "[550]\tvalid_0's rmse: 1.36029\n",
      "[600]\tvalid_0's rmse: 1.36007\n",
      "[650]\tvalid_0's rmse: 1.35897\n",
      "[700]\tvalid_0's rmse: 1.35926\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ kmeans\") #1.3707\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Affinity Propagation\n",
    "af = AffinityPropagation(preference=-50).fit(alldata[flist].values)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "X_train['AfinityProp'] = af.predict(X_train[flist].values)\n",
    "X_test['AfinityProp'] = af.predict(X_test[flist].values)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ affinity \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.5898\n",
      "[100]\tvalid_0's rmse: 1.51796\n",
      "[150]\tvalid_0's rmse: 1.46856\n",
      "[200]\tvalid_0's rmse: 1.43597\n",
      "[250]\tvalid_0's rmse: 1.41387\n",
      "[300]\tvalid_0's rmse: 1.39813\n",
      "[350]\tvalid_0's rmse: 1.38673\n",
      "[400]\tvalid_0's rmse: 1.37921\n",
      "[450]\tvalid_0's rmse: 1.37513\n",
      "[500]\tvalid_0's rmse: 1.37202\n",
      "[550]\tvalid_0's rmse: 1.36955\n",
      "[600]\tvalid_0's rmse: 1.36867\n",
      "[650]\tvalid_0's rmse: 1.36804\n",
      "[700]\tvalid_0's rmse: 1.36803\n",
      "[750]\tvalid_0's rmse: 1.36777\n",
      "[800]\tvalid_0's rmse: 1.3676\n",
      "[850]\tvalid_0's rmse: 1.36803\n",
      "Early stopping, best iteration is:\n",
      "[786]\tvalid_0's rmse: 1.36748\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ affinity \")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "number of estimated clusters : 8\n"
     ]
    }
   ],
   "source": [
    "#means-shift\n",
    "from sklearn import cluster\n",
    "\n",
    "bandwidth = cluster.estimate_bandwidth(alldata, quantile=.3, n_jobs=-1) #adjust here \n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "\n",
    "print(ms.fit_predict(alldata[flist].values))\n",
    "X_train['meanshift'] = ms.predict(X_train[flist].values)\n",
    "X_test['meanshift'] = ms.predict(X_test[flist].values)\n",
    "\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ meanshift\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59129\n",
      "[100]\tvalid_0's rmse: 1.51934\n",
      "[150]\tvalid_0's rmse: 1.47086\n",
      "[200]\tvalid_0's rmse: 1.43767\n",
      "[250]\tvalid_0's rmse: 1.41486\n",
      "[300]\tvalid_0's rmse: 1.39931\n",
      "[350]\tvalid_0's rmse: 1.38907\n",
      "[400]\tvalid_0's rmse: 1.38155\n",
      "[450]\tvalid_0's rmse: 1.37615\n",
      "[500]\tvalid_0's rmse: 1.37274\n",
      "[550]\tvalid_0's rmse: 1.37022\n",
      "[600]\tvalid_0's rmse: 1.36968\n",
      "[650]\tvalid_0's rmse: 1.36899\n",
      "[700]\tvalid_0's rmse: 1.36915\n",
      "[750]\tvalid_0's rmse: 1.36879\n",
      "[800]\tvalid_0's rmse: 1.36855\n",
      "[850]\tvalid_0's rmse: 1.36823\n",
      "[900]\tvalid_0's rmse: 1.36869\n",
      "Early stopping, best iteration is:\n",
      "[820]\tvalid_0's rmse: 1.36808\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ meanshift\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1471)\n",
      "Test set size: (49342, 1471)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"meanshift\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1478)\n",
      "Test set size: (49342, 1478)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ one hot encode\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59466\n",
      "[100]\tvalid_0's rmse: 1.52269\n",
      "[150]\tvalid_0's rmse: 1.47546\n",
      "[200]\tvalid_0's rmse: 1.44197\n",
      "[250]\tvalid_0's rmse: 1.41836\n",
      "[300]\tvalid_0's rmse: 1.40325\n",
      "[350]\tvalid_0's rmse: 1.39365\n",
      "[400]\tvalid_0's rmse: 1.38653\n",
      "[450]\tvalid_0's rmse: 1.38209\n",
      "[500]\tvalid_0's rmse: 1.37968\n",
      "[550]\tvalid_0's rmse: 1.3772\n",
      "[600]\tvalid_0's rmse: 1.37613\n",
      "[650]\tvalid_0's rmse: 1.37552\n",
      "[700]\tvalid_0's rmse: 1.37445\n",
      "[750]\tvalid_0's rmse: 1.37422\n",
      "[800]\tvalid_0's rmse: 1.37424\n",
      "[850]\tvalid_0's rmse: 1.37432\n",
      "Early stopping, best iteration is:\n",
      "[770]\tvalid_0's rmse: 1.37399\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ one hot encode\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Birch\n",
    "birch = Birch(n_clusters=10)\n",
    "birch.fit_predict(X_train[flist].values)\n",
    "X_train['birch'] = birch.predict(X_train[flist].values)\n",
    "X_test['birch'] = birch.predict(X_test[flist].values)\n",
    "\n",
    "#one hot encode clustered varaibles\n",
    "categorical_to_binarizer = [\"birch\"] #probably exclude affinity prop\n",
    "X_train = label_binarizer(X_train, categorical_to_binarizer)\n",
    "X_train = X_train.drop(categorical_to_binarizer, axis=1)\n",
    "\n",
    "X_test = label_binarizer(X_test, categorical_to_binarizer)\n",
    "X_test = X_test.drop(categorical_to_binarizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 1488)\n",
      "Test set size: (49342, 1488)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ birch\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 1.59269\n",
      "[100]\tvalid_0's rmse: 1.52151\n",
      "[150]\tvalid_0's rmse: 1.47268\n",
      "[200]\tvalid_0's rmse: 1.43928\n",
      "[250]\tvalid_0's rmse: 1.41583\n",
      "[300]\tvalid_0's rmse: 1.39998\n",
      "[350]\tvalid_0's rmse: 1.3899\n",
      "[400]\tvalid_0's rmse: 1.38237\n",
      "[450]\tvalid_0's rmse: 1.37808\n",
      "[500]\tvalid_0's rmse: 1.37522\n",
      "[550]\tvalid_0's rmse: 1.37224\n",
      "[600]\tvalid_0's rmse: 1.37111\n",
      "[650]\tvalid_0's rmse: 1.37023\n",
      "[700]\tvalid_0's rmse: 1.37022\n",
      "[750]\tvalid_0's rmse: 1.36988\n",
      "[800]\tvalid_0's rmse: 1.36986\n",
      "[850]\tvalid_0's rmse: 1.36979\n",
      "Early stopping, best iteration is:\n",
      "[763]\tvalid_0's rmse: 1.36949\n"
     ]
    }
   ],
   "source": [
    "print(\"w/ birch\")\n",
    "pred_test_lgbm, model_lgbm, evals_result_lgbm = lgbm_auto(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID        target\n",
      "0  000137c73  2.604974e+06\n",
      "1  00021489f  2.177407e+06\n",
      "2  0004d7953  2.515046e+06\n",
      "3  00056a333  4.243339e+06\n",
      "4  00056d8eb  1.630270e+06\n"
     ]
    }
   ],
   "source": [
    "#LGBM predictions\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test_lgbm\n",
    "\n",
    "sub[\"target\"] = sub_lgb[\"target\"] \n",
    "\n",
    "print(sub.head())\n",
    "sub.to_csv('submit/sub_lgb_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/train_clustered.csv\", index=False)\n",
    "X_test.to_csv('data/test_clustered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
